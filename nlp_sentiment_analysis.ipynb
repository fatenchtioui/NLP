{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMl9gNa03tMOvbzRRQCGy6P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatenchtioui/NLP/blob/main/nlp_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHrMLzk-Dfit",
        "outputId": "737e46fe-bd0e-4acf-a1d5-1100931ece03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 1s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 200, 16)           160000    \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 128)               41472     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 201601 (787.50 KB)\n",
            "Trainable params: 201601 (787.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "157/157 [==============================] - 82s 488ms/step - loss: 0.5079 - accuracy: 0.7349 - val_loss: 0.3191 - val_accuracy: 0.8658\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 73s 468ms/step - loss: 0.2621 - accuracy: 0.8993 - val_loss: 0.2859 - val_accuracy: 0.8804\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 76s 487ms/step - loss: 0.1911 - accuracy: 0.9294 - val_loss: 0.2922 - val_accuracy: 0.8778\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 76s 483ms/step - loss: 0.1575 - accuracy: 0.9456 - val_loss: 0.3326 - val_accuracy: 0.8752\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 73s 469ms/step - loss: 0.1148 - accuracy: 0.9614 - val_loss: 0.3478 - val_accuracy: 0.8718\n",
            "782/782 [==============================] - 32s 41ms/step - loss: 0.3035 - accuracy: 0.8740\n",
            "Accuracy on test set: 0.8740000128746033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Paramètres\n",
        "vocab_size = 10000\n",
        "max_len = 200\n",
        "embedding_dim = 16\n",
        "\n",
        "# Charger le jeu de données IMDb\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "# Rembourrer les séquences pour qu'elles aient toutes la même longueur\n",
        "x_train = pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)\n",
        "\n",
        "# Construire le modèle de Deep Learning pour la classification de texte\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compiler le modèle\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Afficher un résumé du modèle\n",
        "model.summary()\n",
        "\n",
        "# Entraîner le modèle\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Évaluer le modèle sur l'ensemble de test\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Accuracy on test set: {accuracy}\")\n",
        "\n",
        "# Sauvegarder le modèle\n",
        "model.save('nlp_sentiment_analysis_model.h5')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ZG2VS1__Dgav"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}